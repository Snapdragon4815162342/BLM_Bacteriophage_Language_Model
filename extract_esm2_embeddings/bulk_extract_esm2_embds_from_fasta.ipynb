{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2a7e68-ebc2-4633-b9d1-663732fc0aaf",
   "metadata": {},
   "source": [
    "## Codice per estrarre embeddings esm da una cartella contenente file .fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a211b50f-4637-4dce-aaed-55560cfdaa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import esm\n",
    "import time\n",
    "import gc\n",
    "import argparse\n",
    "from esm import Alphabet, FastaBatchedDataset, ProteinBertModel, pretrained\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ecfea6-a41c-4306-81d9-4352d20e1390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model_name, fasta_file, output_dir, tokens_per_batch=4096, seq_length=1022,repr_layers=[33]):\n",
    "    \n",
    "    \n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    # Extract the directory name from the fasta_file path\n",
    "    fasta_file_dir = Path(fasta_file).parent.name\n",
    "    # Construct output file name based on the fasta_file directory name\n",
    "    filename = output_dir / f\"{fasta_file_dir}_proteins_embeddings.pt\"\n",
    "\n",
    "    \n",
    "    model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "    batches = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        collate_fn=alphabet.get_batch_converter(seq_length), \n",
    "        batch_sampler=batches\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_results = {}  # Initialize container for all results\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "\n",
    "            print(f'Processing batch {batch_idx + 1} of {len(batches)}')\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                toks = toks.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "\n",
    "            logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            representations = {layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()}\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                entry_id = label.split()[0]\n",
    "                \n",
    "                #filename = output_dir / f\"{entry_id}.pt\"\n",
    "                truncate_len = min(seq_length, len(strs[i]))\n",
    "\n",
    "                result = {\"entry_id\": entry_id}\n",
    "                result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                all_results[entry_id] = result  # Collect results in dictionary\n",
    "\n",
    "                torch.save(all_results, filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c59eee3-a83d-4844-b8f4-1242e900758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 9\n",
      "Processing batch 2 of 9\n",
      "Processing batch 3 of 9\n",
      "Processing batch 4 of 9\n",
      "Processing batch 5 of 9\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 206.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  Cell \u001b[0;32mIn[3], line 6\u001b[0m\n    extract_embeddings(model_name, fasta_file, output_dir, repr_layers=list(range(0,33)), tokens_per_batch=8192)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[2], line 39\u001b[0m in \u001b[0;35mextract_embeddings\u001b[0m\n    out = model(toks, repr_layers=repr_layers, return_contacts=False)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m in \u001b[0;35m_wrapped_call_impl\u001b[0m\n    return self._call_impl(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m in \u001b[0;35m_call_impl\u001b[0m\n    return forward_call(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\esm\\model\\esm2.py:112\u001b[0m in \u001b[0;35mforward\u001b[0m\n    x, attn = layer(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m in \u001b[0;35m_wrapped_call_impl\u001b[0m\n    return self._call_impl(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m in \u001b[0;35m_call_impl\u001b[0m\n    return forward_call(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\esm\\modules.py:125\u001b[0m in \u001b[0;35mforward\u001b[0m\n    x, attn = self.self_attn(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m in \u001b[0;35m_wrapped_call_impl\u001b[0m\n    return self._call_impl(*args, **kwargs)\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m in \u001b[0;35m_call_impl\u001b[0m\n    return forward_call(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\anaconda3\\envs\\esm\\lib\\site-packages\\esm\\multihead_attention.py:371\u001b[1;36m in \u001b[1;35mforward\u001b[1;36m\n\u001b[1;33m    attn_weights = attn_weights.masked_fill(\u001b[1;36m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m\u001b[1;31m:\u001b[0m CUDA out of memory. Tried to allocate 206.00 MiB. GPU \n"
     ]
    }
   ],
   "source": [
    "model_name = 'esm2_t30_150M_UR50D'\n",
    "#fasta_file = (\"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq/NC_000866.4/NC_000866.4_combined.fasta\")\n",
    "fasta_file = (\"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/AAA/NC_000866.4/NC_000866.4_combined.fasta\")\n",
    "output_dir = (\"C:/Users/lorenzo/Desktop\")\n",
    "\n",
    "extract_embeddings(model_name, fasta_file, output_dir, repr_layers=list(range(0,33)), tokens_per_batch=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5a2fec9-1db4-4741-beca-d0cf881ac00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8987ba54-d0d2-42eb-a78a-5fa7128b694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = torch.load(\"C:/Users/lorenzo/Desktop/embds/NC_000866.4_proteins_embeddings.pt\")\n",
    "#e = e['mean_representations'].numpy()\n",
    "#type(e['mean_representations'][5])\n",
    "#print(e[NP_049878.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc8171f-17c9-46ef-9b5b-7ca84df2e801",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "30",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\n\u001b[1;33m    e[30]\u001b[1;36m\n",
      "\u001b[1;31mKeyError\u001b[0m\u001b[1;31m:\u001b[0m 30\n"
     ]
    }
   ],
   "source": [
    "e[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7277d0-f7c8-469c-9029-377941e72d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 16\n",
      "Processing batch 2 of 16\n",
      "Processing batch 3 of 16\n",
      "Processing batch 4 of 16\n",
      "Processing batch 5 of 16\n",
      "Processing batch 6 of 16\n",
      "Processing batch 7 of 16\n",
      "Processing batch 8 of 16\n",
      "Processing batch 9 of 16\n",
      "Processing batch 10 of 16\n",
      "Processing batch 11 of 16\n",
      "Processing batch 12 of 16\n",
      "Processing batch 13 of 16\n",
      "Processing batch 14 of 16\n",
      "Processing batch 15 of 16\n",
      "Processing batch 16 of 16\n",
      "Processing batch 1 of 2\n",
      "Processing batch 2 of 2\n",
      "Processing batch 1 of 5\n",
      "Processing batch 2 of 5\n",
      "Processing batch 3 of 5\n",
      "Processing batch 4 of 5\n",
      "Processing batch 5 of 5\n",
      "Processing batch 1 of 5\n",
      "Processing batch 2 of 5\n",
      "Processing batch 3 of 5\n",
      "Processing batch 4 of 5\n",
      "Processing batch 5 of 5\n",
      "Processing batch 1 of 5\n",
      "Processing batch 2 of 5\n",
      "Processing batch 3 of 5\n",
      "Processing batch 4 of 5\n",
      "Processing batch 5 of 5\n",
      "Processing batch 1 of 7\n",
      "Processing batch 2 of 7\n",
      "Processing batch 3 of 7\n",
      "Processing batch 4 of 7\n",
      "Processing batch 5 of 7\n",
      "Processing batch 6 of 7\n",
      "Processing batch 7 of 7\n",
      "Processing batch 1 of 6\n",
      "Processing batch 2 of 6\n",
      "Processing batch 3 of 6\n",
      "Processing batch 4 of 6\n",
      "Processing batch 5 of 6\n",
      "Processing batch 6 of 6\n",
      "Processing batch 1 of 5\n",
      "Processing batch 2 of 5\n",
      "Processing batch 3 of 5\n",
      "Processing batch 4 of 5\n",
      "Processing batch 5 of 5\n",
      "Processing batch 1 of 5\n",
      "Processing batch 2 of 5\n",
      "Processing batch 3 of 5\n",
      "Processing batch 4 of 5\n",
      "Processing batch 5 of 5\n",
      "Processing batch 1 of 2\n",
      "Processing batch 2 of 2\n"
     ]
    }
   ],
   "source": [
    "model_name = 'esm2_t30_150M_UR50D'\n",
    "base_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/AAA\"\n",
    "times = []\n",
    "for root, dirs, files in os.walk(base_directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        #print(file_path)\n",
    "        #dir_name = os.path.basename(root)\n",
    "        #print(root)\n",
    "        temp = time.time()\n",
    "        extract_embeddings(model_name, file_path, root, repr_layers=[30])\n",
    "        times.append(time.time() - temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8b2860-811c-4c2c-a8ab-330fda27d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1709901094436646\n",
      "estimated_time 103.3092310877641 hours\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(statistics.mean(times))\n",
    "print(\"estimated_time \" + (str(statistics.mean(times) * 4636/60/60*13)) +\" hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24c181ed-b4b1-477a-b9d5-bdaac372b7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(e)\n",
    "print(e[\"NP_049878.1\"][\"mean_representations\"][30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ab450-be08-4818-8690-4cf2e681a851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip install scikit-learn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Convert list of tensors to a single tensor\n",
    "data_tensor = torch.stack(sequence_representations)\n",
    "\n",
    "# Convert PyTorch tensor to NumPy array\n",
    "data = data_tensor.numpy()\n",
    "\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(data)\n",
    "\n",
    "# Step 2: Perform PCA\n",
    "pca = PCA(n_components=2)  # Reducing to 2 components for 2D plotting\n",
    "principal_components = pca.fit_transform(data_standardized)\n",
    "\n",
    "# Step 3: Plot the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(principal_components[:, 0], principal_components[:, 1], c='blue', marker='o')\n",
    "plt.title('PCA of Numerical Vectors')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04824e-2964-4d5f-8144-8d8eef729e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "# Convert list of tensors to a 2D numpy array\n",
    "data = np.array(torch.stack(sequence_representations))\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "data_2d = tsne.fit_transform(data)\n",
    "\n",
    "# Plot the t-SNE results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1], c='blue', edgecolor='k')\n",
    "plt.title('t-SNE visualization of tensors')\n",
    "plt.xlabel('t-SNE component 1')\n",
    "plt.ylabel('t-SNE component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26d8a8d1-e80d-4bb4-ba55-6b0311fda807",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# COMBINE FASTA FILES #############\n",
    "\n",
    "import os\n",
    "\n",
    "def combine_fasta_files(input_directory, output_file):\n",
    "    seen_labels = set()\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for root, dirs, files in os.walk(input_directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".fasta\") or file.endswith(\".fa\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    with open(file_path, 'r') as infile:\n",
    "                        write_data = False\n",
    "                        for line in infile:\n",
    "                            if line.startswith(\">\"):\n",
    "                                label = line.strip()\n",
    "                                if label not in seen_labels:\n",
    "                                    seen_labels.add(label)\n",
    "                                    outfile.write(line)\n",
    "                                    write_data = True\n",
    "                                else:\n",
    "                                    write_data = False\n",
    "                            elif write_data:\n",
    "                                outfile.write(line)\n",
    "# Example usage\n",
    "#input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq/NC_000866.4\"\n",
    "#output_file = 'C:/Users/lorenzo/Desktop/one_bacter_proteins.fasta'\n",
    "#combine_fasta_files(input_directory, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af271881-f6be-4bfc-bf69-f1aa19f57f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq\"\n",
    "output_file = 'C:/Users/lorenzo/Desktop/one_bacter_proteins.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af8d3d55-107d-4f89-9bac-b649b91e223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_fasta_files(input_directory, exclude_file):\n",
    "    print (\"exclude_file: \" + exclude_file)\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if not (\"combined\" in file):\n",
    "                os.remove(os.path.join(root, file))\n",
    "                print(\"deleting : \" + file)\n",
    "\n",
    "def process_subfolders_recursively(base_directory):\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        # Only process subfolders, skip the root folder\n",
    "        for subdir in dirs:\n",
    "            subfolder_path = os.path.join(root, subdir)\n",
    "            output_file = os.path.join(subfolder_path, f\"{subdir}_combined.fasta\")\n",
    "            combine_fasta_files(subfolder_path, output_file)\n",
    "            delete_fasta_files(subfolder_path, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49feaae4-5477-4e2d-b092-e07ca4efd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "############# COMBINE FASTA FILES #############\n",
    "# Sostituisce tutti i singoli file .fasta con un unico file _combined.fasta\n",
    "\n",
    "import os\n",
    "\n",
    "input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq\"\n",
    "\n",
    "def combine_fasta_files(input_directory, output_file):\n",
    "    seen_labels = set()\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for root, dirs, files in os.walk(input_directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".fasta\") or file.endswith(\".fa\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    with open(file_path, 'r') as infile:\n",
    "                        write_data = False\n",
    "                        for line in infile:\n",
    "                            if line.startswith(\">\"):\n",
    "                                label = line.strip()\n",
    "                                if label not in seen_labels:\n",
    "                                    seen_labels.add(label)\n",
    "                                    outfile.write(line)\n",
    "                                    write_data = True\n",
    "                                else:\n",
    "                                    write_data = False\n",
    "                            elif write_data:\n",
    "                                outfile.write(line)\n",
    "\n",
    "def delete_fasta_files(input_directory, exclude_file):\n",
    "    #print (\"exclude_file: \" + exclude_file)\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if not (\"combined\" in file):\n",
    "                os.remove(os.path.join(root, file))\n",
    "                #print(\"deleting : \" + file)\n",
    "\n",
    "def process_subfolders_recursively(base_directory):\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        # Only process subfolders, skip the root folder\n",
    "        for subdir in dirs:\n",
    "            subfolder_path = os.path.join(root, subdir)\n",
    "            output_file = os.path.join(subfolder_path, f\"{subdir}_combined.fasta\")\n",
    "            combine_fasta_files(subfolder_path, output_file)\n",
    "            delete_fasta_files(subfolder_path, output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ba5d60-89a1-47e2-8736-ae9790b56b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# COMBINE FASTA FILES FAST #############\n",
    "\n",
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "#input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq\"\n",
    "\n",
    "def process_file(file_path, seen_labels):\n",
    "    combined_data = []\n",
    "    with open(file_path, 'r') as infile:\n",
    "        write_data = False\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                label = line.strip()\n",
    "                if label not in seen_labels:\n",
    "                    seen_labels.add(label)\n",
    "                    combined_data.append(line)\n",
    "                    write_data = True\n",
    "                else:\n",
    "                    write_data = False\n",
    "            elif write_data:\n",
    "                combined_data.append(line)\n",
    "    return combined_data\n",
    "\n",
    "def combine_fasta_files(input_directory, output_file):\n",
    "    seen_labels = set()\n",
    "    combined_data = []\n",
    "\n",
    "    # Use ThreadPoolExecutor to process files in parallel\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for root, dirs, files in os.walk(input_directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\".fasta\") or file.endswith(\".fa\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    futures.append(executor.submit(process_file, file_path, seen_labels))\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            combined_data.extend(future.result())\n",
    "    \n",
    "    with open(output_file, 'w') as outfile:\n",
    "        outfile.writelines(combined_data)\n",
    "\n",
    "def delete_fasta_files(input_directory, exclude_file):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            if not \"combined\" in file and (file.endswith(\".fasta\") or file.endswith(\".fa\")):\n",
    "                file_path = os.path.join(root, file)\n",
    "                os.remove(file_path)\n",
    "                #print(f\"Deleting: {file}\")\n",
    "\n",
    "def process_subfolders_recursively_fast(base_directory):\n",
    "    for root, dirs, files in os.walk(base_directory):\n",
    "        # Only process subfolders, skip the root folder\n",
    "        for subdir in dirs:\n",
    "            subfolder_path = os.path.join(root, subdir)\n",
    "            output_file = os.path.join(subfolder_path, f\"{subdir}_combined.fasta\")\n",
    "            combine_fasta_files(subfolder_path, output_file)\n",
    "            delete_fasta_files(subfolder_path, output_file)\n",
    "\n",
    "#process_subfolders_recursively(input_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65caa8e9-882e-4716-a480-943e3c00ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed normal: 12.826902151107788\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "\n",
    "input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/AAA\"\n",
    "start = time.time()\n",
    "process_subfolders_recursively(input_directory)\n",
    "print(\"elapsed normal: \" +  str(time.time() - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e3c25-b077-49c2-9363-1e7d3ac18bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95114f2-0f74-4d12-b054-c1844f980520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed fast: 638.7071475982666\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"C:/Users/lorenzo/Desktop/phagescope/FASTA/protein_fasta/RefSeq\"\n",
    "start = time.time()\n",
    "process_subfolders_recursively_fast(input_directory)\n",
    "print(\"elapsed fast: \" +  str(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a08ad-3ba5-4a0c-8b82-741d1230e7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
